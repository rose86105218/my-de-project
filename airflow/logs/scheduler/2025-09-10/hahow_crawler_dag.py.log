[2025-09-10T22:37:10.734+0800] INFO - processor.py:186 - _handle_dag_file_processing() - Started process (PID=144) to work on /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-10T22:37:10.736+0800] INFO - processor.py:914 - process_file() - Processing file /opt/airflow/dags/hahow_crawler_dag.py for tasks to queue
[2025-09-10T22:37:10.742+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-10T22:37:10.742+0800] INFO - dagbag.py:588 - collect_dags() - Filling up the DagBag from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-10T22:37:12.782+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-10T22:37:12.779+0800] ERROR - dagbag.py:387 - parse() - Failed to import: /opt/airflow/dags/hahow_crawler_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/hahow_crawler_dag.py", line 12, in <module>
    from data_ingestion.hahow_crawler_course_optimized_sales import crawler_hahow_course
  File "/opt/airflow/data_ingestion/hahow_crawler_course_optimized_sales.py", line 8, in <module>
    from data_ingestion.mysql import upload_data_to_mysql, upload_data_to_mysql_insert, upload_data_to_mysql_upsert, course_table, course_sales_table
ImportError: cannot import name 'upload_data_to_mysql_insert' from 'data_ingestion.mysql' (/opt/airflow/data_ingestion/mysql.py)
[2025-09-10T22:37:12.783+0800] WARNING - processor.py:927 - process_file() - No viable dags retrieved from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-10T22:37:12.837+0800] INFO - processor.py:208 - _run_file_processor() - Processing /opt/airflow/dags/hahow_crawler_dag.py took 2.113 seconds
[2025-09-10T22:37:42.919+0800] INFO - processor.py:186 - _handle_dag_file_processing() - Started process (PID=218) to work on /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-10T22:37:42.920+0800] INFO - processor.py:914 - process_file() - Processing file /opt/airflow/dags/hahow_crawler_dag.py for tasks to queue
[2025-09-10T22:37:42.923+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-10T22:37:42.922+0800] INFO - dagbag.py:588 - collect_dags() - Filling up the DagBag from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-10T22:37:43.459+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-10T22:37:43.457+0800] ERROR - dagbag.py:387 - parse() - Failed to import: /opt/airflow/dags/hahow_crawler_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/hahow_crawler_dag.py", line 12, in <module>
    from data_ingestion.hahow_crawler_course_optimized_sales import crawler_hahow_course
  File "/opt/airflow/data_ingestion/hahow_crawler_course_optimized_sales.py", line 8, in <module>
    from data_ingestion.mysql import upload_data_to_mysql, upload_data_to_mysql_insert, upload_data_to_mysql_upsert, course_table, course_sales_table
ImportError: cannot import name 'upload_data_to_mysql_insert' from 'data_ingestion.mysql' (/opt/airflow/data_ingestion/mysql.py)
[2025-09-10T22:37:43.459+0800] WARNING - processor.py:927 - process_file() - No viable dags retrieved from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-10T22:37:43.480+0800] INFO - processor.py:208 - _run_file_processor() - Processing /opt/airflow/dags/hahow_crawler_dag.py took 0.568 seconds
[2025-09-10T22:38:14.083+0800] INFO - processor.py:186 - _handle_dag_file_processing() - Started process (PID=292) to work on /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-10T22:38:14.085+0800] INFO - processor.py:914 - process_file() - Processing file /opt/airflow/dags/hahow_crawler_dag.py for tasks to queue
[2025-09-10T22:38:14.086+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-10T22:38:14.086+0800] INFO - dagbag.py:588 - collect_dags() - Filling up the DagBag from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-10T22:38:14.676+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-10T22:38:14.675+0800] ERROR - dagbag.py:387 - parse() - Failed to import: /opt/airflow/dags/hahow_crawler_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/hahow_crawler_dag.py", line 12, in <module>
    from data_ingestion.hahow_crawler_course_optimized_sales import crawler_hahow_course
  File "/opt/airflow/data_ingestion/hahow_crawler_course_optimized_sales.py", line 8, in <module>
    from data_ingestion.mysql import upload_data_to_mysql, upload_data_to_mysql_insert, upload_data_to_mysql_upsert, course_table, course_sales_table
ImportError: cannot import name 'upload_data_to_mysql_insert' from 'data_ingestion.mysql' (/opt/airflow/data_ingestion/mysql.py)
[2025-09-10T22:38:14.677+0800] WARNING - processor.py:927 - process_file() - No viable dags retrieved from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-10T22:38:14.700+0800] INFO - processor.py:208 - _run_file_processor() - Processing /opt/airflow/dags/hahow_crawler_dag.py took 0.622 seconds
[2025-09-10T22:38:45.034+0800] INFO - processor.py:186 - _handle_dag_file_processing() - Started process (PID=366) to work on /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-10T22:38:45.038+0800] INFO - processor.py:914 - process_file() - Processing file /opt/airflow/dags/hahow_crawler_dag.py for tasks to queue
[2025-09-10T22:38:45.042+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-10T22:38:45.041+0800] INFO - dagbag.py:588 - collect_dags() - Filling up the DagBag from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-10T22:38:45.763+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-10T22:38:45.761+0800] ERROR - dagbag.py:387 - parse() - Failed to import: /opt/airflow/dags/hahow_crawler_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/hahow_crawler_dag.py", line 12, in <module>
    from data_ingestion.hahow_crawler_course_optimized_sales import crawler_hahow_course
  File "/opt/airflow/data_ingestion/hahow_crawler_course_optimized_sales.py", line 8, in <module>
    from data_ingestion.mysql import upload_data_to_mysql, upload_data_to_mysql_insert, upload_data_to_mysql_upsert, course_table, course_sales_table
ImportError: cannot import name 'upload_data_to_mysql_insert' from 'data_ingestion.mysql' (/opt/airflow/data_ingestion/mysql.py)
[2025-09-10T22:38:45.763+0800] WARNING - processor.py:927 - process_file() - No viable dags retrieved from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-10T22:38:45.785+0800] INFO - processor.py:208 - _run_file_processor() - Processing /opt/airflow/dags/hahow_crawler_dag.py took 0.760 seconds
[2025-09-10T22:39:15.876+0800] INFO - processor.py:186 - _handle_dag_file_processing() - Started process (PID=440) to work on /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-10T22:39:15.877+0800] INFO - processor.py:914 - process_file() - Processing file /opt/airflow/dags/hahow_crawler_dag.py for tasks to queue
[2025-09-10T22:39:15.878+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-10T22:39:15.878+0800] INFO - dagbag.py:588 - collect_dags() - Filling up the DagBag from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-10T22:39:16.523+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-10T22:39:16.523+0800] ERROR - dagbag.py:387 - parse() - Failed to import: /opt/airflow/dags/hahow_crawler_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/hahow_crawler_dag.py", line 12, in <module>
    from data_ingestion.hahow_crawler_course_optimized_sales import crawler_hahow_course
  File "/opt/airflow/data_ingestion/hahow_crawler_course_optimized_sales.py", line 8, in <module>
    from data_ingestion.mysql import upload_data_to_mysql, upload_data_to_mysql_insert, upload_data_to_mysql_upsert, course_table, course_sales_table
ImportError: cannot import name 'upload_data_to_mysql_insert' from 'data_ingestion.mysql' (/opt/airflow/data_ingestion/mysql.py)
[2025-09-10T22:39:16.524+0800] WARNING - processor.py:927 - process_file() - No viable dags retrieved from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-10T22:39:16.552+0800] INFO - processor.py:208 - _run_file_processor() - Processing /opt/airflow/dags/hahow_crawler_dag.py took 0.684 seconds
[2025-09-10T22:39:47.484+0800] INFO - processor.py:186 - _handle_dag_file_processing() - Started process (PID=514) to work on /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-10T22:39:47.487+0800] INFO - processor.py:914 - process_file() - Processing file /opt/airflow/dags/hahow_crawler_dag.py for tasks to queue
[2025-09-10T22:39:47.489+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-10T22:39:47.488+0800] INFO - dagbag.py:588 - collect_dags() - Filling up the DagBag from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-10T22:39:48.006+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-10T22:39:48.004+0800] ERROR - dagbag.py:387 - parse() - Failed to import: /opt/airflow/dags/hahow_crawler_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/hahow_crawler_dag.py", line 12, in <module>
    from data_ingestion.hahow_crawler_course_optimized_sales import crawler_hahow_course
  File "/opt/airflow/data_ingestion/hahow_crawler_course_optimized_sales.py", line 8, in <module>
    from data_ingestion.mysql import upload_data_to_mysql, upload_data_to_mysql_insert, upload_data_to_mysql_upsert, course_table, course_sales_table
ImportError: cannot import name 'upload_data_to_mysql_insert' from 'data_ingestion.mysql' (/opt/airflow/data_ingestion/mysql.py)
[2025-09-10T22:39:48.007+0800] WARNING - processor.py:927 - process_file() - No viable dags retrieved from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-10T22:39:48.037+0800] INFO - processor.py:208 - _run_file_processor() - Processing /opt/airflow/dags/hahow_crawler_dag.py took 0.564 seconds
[2025-09-10T22:40:18.752+0800] INFO - processor.py:186 - _handle_dag_file_processing() - Started process (PID=588) to work on /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-10T22:40:18.753+0800] INFO - processor.py:914 - process_file() - Processing file /opt/airflow/dags/hahow_crawler_dag.py for tasks to queue
[2025-09-10T22:40:18.754+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-10T22:40:18.754+0800] INFO - dagbag.py:588 - collect_dags() - Filling up the DagBag from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-10T22:40:19.249+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-10T22:40:19.247+0800] ERROR - dagbag.py:387 - parse() - Failed to import: /opt/airflow/dags/hahow_crawler_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/hahow_crawler_dag.py", line 12, in <module>
    from data_ingestion.hahow_crawler_course_optimized_sales import crawler_hahow_course
  File "/opt/airflow/data_ingestion/hahow_crawler_course_optimized_sales.py", line 8, in <module>
    from data_ingestion.mysql import upload_data_to_mysql, upload_data_to_mysql_insert, upload_data_to_mysql_upsert, course_table, course_sales_table
ImportError: cannot import name 'upload_data_to_mysql_insert' from 'data_ingestion.mysql' (/opt/airflow/data_ingestion/mysql.py)
[2025-09-10T22:40:19.249+0800] WARNING - processor.py:927 - process_file() - No viable dags retrieved from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-10T22:40:19.279+0800] INFO - processor.py:208 - _run_file_processor() - Processing /opt/airflow/dags/hahow_crawler_dag.py took 0.534 seconds
[2025-09-10T22:40:50.096+0800] INFO - processor.py:186 - _handle_dag_file_processing() - Started process (PID=662) to work on /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-10T22:40:50.102+0800] INFO - processor.py:914 - process_file() - Processing file /opt/airflow/dags/hahow_crawler_dag.py for tasks to queue
[2025-09-10T22:40:50.103+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-10T22:40:50.103+0800] INFO - dagbag.py:588 - collect_dags() - Filling up the DagBag from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-10T22:40:50.566+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-10T22:40:50.564+0800] ERROR - dagbag.py:387 - parse() - Failed to import: /opt/airflow/dags/hahow_crawler_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/hahow_crawler_dag.py", line 12, in <module>
    from data_ingestion.hahow_crawler_course_optimized_sales import crawler_hahow_course
  File "/opt/airflow/data_ingestion/hahow_crawler_course_optimized_sales.py", line 8, in <module>
    from data_ingestion.mysql import upload_data_to_mysql, upload_data_to_mysql_insert, upload_data_to_mysql_upsert, course_table, course_sales_table
ImportError: cannot import name 'upload_data_to_mysql_insert' from 'data_ingestion.mysql' (/opt/airflow/data_ingestion/mysql.py)
[2025-09-10T22:40:50.566+0800] WARNING - processor.py:927 - process_file() - No viable dags retrieved from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-10T22:40:50.593+0800] INFO - processor.py:208 - _run_file_processor() - Processing /opt/airflow/dags/hahow_crawler_dag.py took 0.504 seconds
[2025-09-10T22:41:21.506+0800] INFO - processor.py:186 - _handle_dag_file_processing() - Started process (PID=736) to work on /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-10T22:41:21.508+0800] INFO - processor.py:914 - process_file() - Processing file /opt/airflow/dags/hahow_crawler_dag.py for tasks to queue
[2025-09-10T22:41:21.510+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-10T22:41:21.510+0800] INFO - dagbag.py:588 - collect_dags() - Filling up the DagBag from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-10T22:41:21.958+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-10T22:41:21.956+0800] ERROR - dagbag.py:387 - parse() - Failed to import: /opt/airflow/dags/hahow_crawler_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/hahow_crawler_dag.py", line 12, in <module>
    from data_ingestion.hahow_crawler_course_optimized_sales import crawler_hahow_course
  File "/opt/airflow/data_ingestion/hahow_crawler_course_optimized_sales.py", line 8, in <module>
    from data_ingestion.mysql import upload_data_to_mysql, upload_data_to_mysql_insert, upload_data_to_mysql_upsert, course_table, course_sales_table
ImportError: cannot import name 'upload_data_to_mysql_insert' from 'data_ingestion.mysql' (/opt/airflow/data_ingestion/mysql.py)
[2025-09-10T22:41:21.959+0800] WARNING - processor.py:927 - process_file() - No viable dags retrieved from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-10T22:41:21.987+0800] INFO - processor.py:208 - _run_file_processor() - Processing /opt/airflow/dags/hahow_crawler_dag.py took 0.490 seconds
[2025-09-10T22:41:52.799+0800] INFO - processor.py:186 - _handle_dag_file_processing() - Started process (PID=810) to work on /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-10T22:41:52.800+0800] INFO - processor.py:914 - process_file() - Processing file /opt/airflow/dags/hahow_crawler_dag.py for tasks to queue
[2025-09-10T22:41:52.803+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-10T22:41:52.802+0800] INFO - dagbag.py:588 - collect_dags() - Filling up the DagBag from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-10T22:41:53.384+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-10T22:41:53.382+0800] ERROR - dagbag.py:387 - parse() - Failed to import: /opt/airflow/dags/hahow_crawler_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/hahow_crawler_dag.py", line 12, in <module>
    from data_ingestion.hahow_crawler_course_optimized_sales import crawler_hahow_course
  File "/opt/airflow/data_ingestion/hahow_crawler_course_optimized_sales.py", line 8, in <module>
    from data_ingestion.mysql import upload_data_to_mysql, upload_data_to_mysql_insert, upload_data_to_mysql_upsert, course_table, course_sales_table
ImportError: cannot import name 'upload_data_to_mysql_insert' from 'data_ingestion.mysql' (/opt/airflow/data_ingestion/mysql.py)
[2025-09-10T22:41:53.385+0800] WARNING - processor.py:927 - process_file() - No viable dags retrieved from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-10T22:41:53.416+0800] INFO - processor.py:208 - _run_file_processor() - Processing /opt/airflow/dags/hahow_crawler_dag.py took 0.625 seconds
[2025-09-10T22:42:24.253+0800] INFO - processor.py:186 - _handle_dag_file_processing() - Started process (PID=884) to work on /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-10T22:42:24.255+0800] INFO - processor.py:914 - process_file() - Processing file /opt/airflow/dags/hahow_crawler_dag.py for tasks to queue
[2025-09-10T22:42:24.256+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-10T22:42:24.256+0800] INFO - dagbag.py:588 - collect_dags() - Filling up the DagBag from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-10T22:42:24.803+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-10T22:42:24.801+0800] ERROR - dagbag.py:387 - parse() - Failed to import: /opt/airflow/dags/hahow_crawler_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/hahow_crawler_dag.py", line 12, in <module>
    from data_ingestion.hahow_crawler_course_optimized_sales import crawler_hahow_course
  File "/opt/airflow/data_ingestion/hahow_crawler_course_optimized_sales.py", line 8, in <module>
    from data_ingestion.mysql import upload_data_to_mysql, upload_data_to_mysql_insert, upload_data_to_mysql_upsert, course_table, course_sales_table
ImportError: cannot import name 'upload_data_to_mysql_insert' from 'data_ingestion.mysql' (/opt/airflow/data_ingestion/mysql.py)
[2025-09-10T22:42:24.804+0800] WARNING - processor.py:927 - process_file() - No viable dags retrieved from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-10T22:42:24.835+0800] INFO - processor.py:208 - _run_file_processor() - Processing /opt/airflow/dags/hahow_crawler_dag.py took 0.592 seconds
[2025-09-10T22:42:55.640+0800] INFO - processor.py:186 - _handle_dag_file_processing() - Started process (PID=958) to work on /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-10T22:42:55.641+0800] INFO - processor.py:914 - process_file() - Processing file /opt/airflow/dags/hahow_crawler_dag.py for tasks to queue
[2025-09-10T22:42:55.643+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-10T22:42:55.643+0800] INFO - dagbag.py:588 - collect_dags() - Filling up the DagBag from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-10T22:42:56.132+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-10T22:42:56.130+0800] ERROR - dagbag.py:387 - parse() - Failed to import: /opt/airflow/dags/hahow_crawler_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/hahow_crawler_dag.py", line 12, in <module>
    from data_ingestion.hahow_crawler_course_optimized_sales import crawler_hahow_course
  File "/opt/airflow/data_ingestion/hahow_crawler_course_optimized_sales.py", line 8, in <module>
    from data_ingestion.mysql import upload_data_to_mysql, upload_data_to_mysql_insert, upload_data_to_mysql_upsert, course_table, course_sales_table
ImportError: cannot import name 'upload_data_to_mysql_insert' from 'data_ingestion.mysql' (/opt/airflow/data_ingestion/mysql.py)
[2025-09-10T22:42:56.132+0800] WARNING - processor.py:927 - process_file() - No viable dags retrieved from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-10T22:42:56.160+0800] INFO - processor.py:208 - _run_file_processor() - Processing /opt/airflow/dags/hahow_crawler_dag.py took 0.530 seconds
