# de-project
2025 Data Engineering Course Project
>è€å¸«åŸå§‹githubï¼š https://github.com/DataEngCamp/de-project



## è³‡æ–™å¤¾çµæ§‹
```
de-project/
â”œâ”€â”€ .venv/                                   # Python è™›æ“¬ç’°å¢ƒ
â”œâ”€â”€ .gitignore                               # Git å¿½ç•¥æª”æ¡ˆè¨­å®š
â”œâ”€â”€ .python-version                          # Python ç‰ˆæœ¬æŒ‡å®š
â”œâ”€â”€ README.md                                # å°ˆæ¡ˆèªªæ˜æ–‡ä»¶
â”œâ”€â”€ pyproject.toml                           # Python å°ˆæ¡ˆé…ç½®æª”
â”œâ”€â”€ uv.lock                                  # UV å¥—ä»¶ç®¡ç†é–å®šæª”
â”‚
â”œâ”€â”€ data_ingestion/                          # ğŸ”¥ æ ¸å¿ƒè³‡æ–™æ“·å–æ¨¡çµ„
â”‚   â”œâ”€â”€ __init__.py                          # Python å¥—ä»¶åˆå§‹åŒ–
â”‚   â”œâ”€â”€ config.py                            # é…ç½®æª”ï¼ˆç’°å¢ƒè®Šæ•¸ï¼‰
â”‚   â”œâ”€â”€ worker.py                            # Celery Worker è¨­å®š
â”‚   â”œâ”€â”€ tasks.py                             # Celery ä»»å‹™å®šç¾©
â”‚   â””â”€â”€ producer.py                          # åŸºæœ¬ Producer
â”‚
â””â”€â”€ docker-compose-broker.yml               # RabbitMQ Broker é…ç½®
```



## æŒ‡ä»¤
```
# å»ºç«‹è™›æ“¬ç’°å¢ƒä¸¦å®‰è£ä¾è³´ï¼ˆåŒæ­¥ï¼‰(åªéœ€è¦ç¬¬ä¸€æ¬¡ & ä¾è³´æ›´æ–°æ™‚åŸ·è¡Œï¼Œä¸ç”¨æ¯æ¬¡é–‹ VS Code éƒ½è·‘)
uv sync

# å»ºç«‹ä¸€å€‹ network è®“å„æœå‹™èƒ½æºé€š
docker network create my_network

# å•Ÿå‹•æœå‹™
docker compose -f docker-compose-broker.yml up -d

# åœæ­¢ä¸¦ç§»é™¤æœå‹™
docker compose -f docker-compose-broker.yml down

ï¼ƒ æŸ¥çœ‹æœå‹™ logs
docker logs -f rabbitmq
docker logs -f flower

# å•Ÿå‹• worker
uv run celery -A data_ingestion.worker worker --loglevel=info --concurrency=4 --hostname=worker1@%h -Q get_danmu 
uv run celery -A data_ingestion.worker worker --loglevel=info --concurrency=4 --hostname=worker2@%h -Q get_danmu

--concurrency=4 â†’ æ¯å€‹ worker é–‹ 4 å€‹ process
--hostname=worker1%h â†’ è¨­å®š worker åç¨±ï¼Œ%hæ˜¯ä¸»æ©Ÿåï¼Œå¤šå°ä¸»æ©Ÿæ™‚å¯é¿å…workeråå­—è¡çª
-Q get_danmu â†’ åªç›£æ§é€™å€‹ queue

# producer ç™¼é€ä»»å‹™
uv run data_ingestion/producer_get_danmu.py

*ä¸€èˆ¬å»ºè­°å…ˆå•Ÿå‹•workerï¼Œå†ç”¨producerç™¼é€ä»»å‹™
```

## task, producer, workerè¨­å®š
```
1. task (å–®ä¸€ä»»å‹™å–®ä½)
-from data_ingestion.worker import app
-åœ¨def()å‰éœ€è¦åŠ ä¸Š@app.task()ï¼Œç”¨ä¾†è¨»å†Šä»»å‹™ï¼Œè®“å‡½å¼å¯ä»¥è¢«celeryå‘¼å«

2. producer (ä¸Ÿä»»å‹™çš„äºº)
-from data_ingestion.æ”¾ç½®taskçš„pyæª”åå­— import å‡½å¼(æœ‰ç”¨@app.taskè¨»å†Šéçš„)
éœ€è¦åŠ ä¸Šfrom data_ingestion.tasks_crawler_hahow_course import crawler_hahow_course
-å‡½å¼.delay("è®Šæ•¸")
ä»£è¡¨è¦ä¸Ÿçµ¦CeleryåŸ·è¡Œï¼Œå¦‚ï¼šcrawler_hahow_course.delay("programing") 

3. worker (æ¥æ”¶ä¸¦åŸ·è¡Œä»»å‹™çš„äºº)
-åœ¨appè£¡åŠ ä¸Šæœ‰å«taskçš„pyæª”
-æ³¨æ„æ˜¯å«taskçš„pyæª”ï¼Œè€Œä¸æ˜¯å–®ä¸€task (ä¸ç„¶Celeryæœƒæ‰¾ä¸åˆ°taskä½ç½®)ï¼Œä¸”ä¸€å€‹pyæª”ä¹Ÿå¯èƒ½æœ‰å¤šå€‹task

app = Celery(
    main="worker",
    include=[
        "data_ingestion.tasks",
        "data_ingestion.tasks_crawler_hahow_course",
        "data_ingestion.tasks_crawler_hahow_article",
    ],
```
