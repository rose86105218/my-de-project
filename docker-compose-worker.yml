version: '3.0'  # 使用 Docker Compose 的版本 3.0，適合大部分部署場景

services:
  worker:  # 定義一個服務，名稱為 crawler_twse
    image: enzochang/data_ingestion:latest  # 使用的映像檔名稱與標籤（版本）
    container_name: "crawler_hahow_worker"  # 設定 container_name = crawler_hahow_worker  
    command: uv run celery -A data_ingestion.worker worker --loglevel=info --hostname=worker%h
    # 啟動容器後執行的命令，這裡是啟動 Celery worker，指定 app 為 data_ingestion.worker，設定日誌等級為 info，

    restart: always  # 若容器停止或崩潰，自動重新啟動
    environment:
      - TZ=Asia/Taipei  # 設定時區為台北（UTC+8）
      - RABBITMQ_HOST=rabbitmq
    networks:
      - my_network  # 將此服務連接到 my_network 網路
    volumes:
      - ./output:/app/output

networks:
  my_network:  # 定義一個名為 my_network 的自訂網路，其他服務也可加入此網路
    # 加入已經存在的網路
    external: true
